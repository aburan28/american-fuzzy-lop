#summary Tips for understanding the status screen

=american fuzzy lop: understanding the status screen=

When running `afl-fuzz`, the status screen should look roughly the following way:

{{{

                       american fuzzy lop 0.39b (xmllint)

┌─ process timing ─────────────────────────────────────┬─ overall results ─────┐
│        run time : 0 days, 8 hrs, 32 min, 43 sec      │  cycles done : 0      │
│   last new path : 0 days, 0 hrs, 6 min, 40 sec       │  total paths : 2095   │
│ last uniq crash : none seen yet                      │ uniq crashes : 0      │
│  last uniq hang : 0 days, 1 hrs, 24 min, 32 sec      │   uniq hangs : 19     │
├─ cycle progress ────────────────────┬─ map coverage ─┴───────────────────────┤
│  now processing : 1296 (61.86%)     │    map density : 4763 (29.07%)         │
│ paths timed out : 0 (0.00%)         │ count coverage : 4.03 bits/tuple       │
├─ stage progress ────────────────────┼─ findings in depth ────────────────────┤
│  now trying : interest 32/8         │ favored paths : 879 (41.96%)           │
│ stage execs : 3996/34.4k (11.62%)   │  new edges on : 423 (20.19%)           │
│ total execs : 27.4M                 │ total crashes : 0 (0 unique)           │
│  exec speed : 891.7/sec             │   total hangs : 24 (19 unique)         │
├─ fuzzing strategy yields ───────────┴───────────────┬─ path geometry ────────┤
│   bit flips : 57/289k, 18/289k, 18/288k             │   levels : 5           │
│  byte flips : 0/36.2k, 4/35.7k, 7/34.6k             │  pending : 1570        │
│ arithmetics : 53/2.54M, 0/537k, 0/55.2k             │ pend fav : 583         │
│  known ints : 8/322k, 12/1.32M, 10/1.70M            │   latent : 0           │
│       havoc : 1903/20.0M, 0/0                       │ variable : 0           │
└─────────────────────────────────────────────────────┴────────────────────────┘
}}}

This page provides an overview for each of the displayed stats.

==Process timing==

This section is fairly self-explanatory: it tells you how run the fuzzer has been running and how much time has elapsed since its most recent finds. This is broken down into "paths" (a shorthand for test cases that trigger new execution patterns), crashes, and hangs.

When it comes to timing: there is no hard rule, but most fuzzing jobs should be expected to run for days or weeks; every now and then, some will be allowed to run for months.

There's one important thing to watch out for: if the tool is not finding new paths within several minutes of starting, you're probably not invoking the target binary correctly and it never gets to parse the input files we're throwing at it. If that's the case, you will eventually see a big red warning in this section, too.

==Overall results==

The first field in this section gives you the count of queue passes done so far - that is, the number of times the fuzzer went over all the interesting test cases, fuzzed them, and looped back. Every fuzzing session should be allowed to complete at least one cycle - and ideally, much more than that.

The remaining fields should be pretty obvious: there's the number of test cases ("paths") discovered so far, and the number of unique faults. The test cases, crashes, and hangs can be explored in real-time by browsing the output directory.

==Cycle progress==

This tells you how far along the fuzzer is with the current queue cycle: the test case it is currently working on, plus the number of inputs it decided to ditch because they were persistently timing out.

==Map coverage==

The section provides some trivia about the instrumentation embedded in the target binary. The first one tells you how many branch tuples we have already hit, in proportion to how much the bitmap can hold (ideally, this should be between 5 and 30%). The other deals with the variability in tuple hit counts. If we are seeing just one hit count per each tuple, this will read 1; if we're seeing full ranges everywhere, it will go up to 8.

==Stage progress==

This is the in-depth peek at what the fuzzer is actually doing right now. It tells you about the current stage, which can be any of:

  * `init` - if you see this, you're pretty amazing, because it flashes on the screen for a millisecond or so.

  * `calibration` - a pre-fuzzing stage where the execution path is examined to detect anomalies.

  * `bitflip L/S` - deterministic bit flips. There are L bits toggled at any given time, walking the input file at S-bit increments. The current L/S variants are: 1/1, 2/1, 4/1, 8/8, 16/8, 32/8.

  * `arith L/8` - deterministic arithmetics. The fuzzer tries to subtract or add small integers to 8-, 16-, and 32-bit values. The steopver is always 8 bits.

  * `interest L/8` - deterministic value overwrite. The fuzzer has a list of known "interesting" 8-, 16-, and 32-bit values to try. The stepover is 8 bits.

  * `havoc` - a sort-of-fixed-length cycle with stacked random tweaks. The operations attempted during this stage include bit flips, overwrites with random and "interesting" integers, block deletion, and block duplication.

  * `splice` - a last-resort strategy that kicks in after a full queue cycle with no new paths. It is equivalent to havoc, except that it first splices together two random inputs from the queue at some arbitrarily selected midpoint.

The remaining fields should be fairly self-evident: there's the exec count progress indicator for the current stage, a global exec counter, and a benchmark for program execution speed. That benchmark should be ideally over 500 execs/sec - and if it drops below 100, the job will probably take very long time.

The fuzzer will explicitly warn you about slow targets, too. Possible ideas include setting more aggressive timeouts, using simpler test cases, or using `strace` on the target binary to figure out what the bottlenecks are. If all else fails, running `afl-fuzz` with the `-d` option may offer relief.

==Findings in depth==

This gives you several metrics that are of interest mostly to complete nerds. The section includes the number of paths that the fuzzer likes the most based on a minimization algorithm baked into the code (these will get more air time), the number of test cases that actually result in better edge coverage (versus just pushing the hit counters up), and additional counters for crashes and hangs.

==Fuzzing strategy yields==

This is just another nerd-targeted section keeping track of how many paths we have netted, in proportion to the number of execs attempted, for each and fuzzing strategy discussed above. This serves to scientifically validate assumptions about the usefulness of the approaches taken by `afl-fuzz`.

==Path geometry==

The first field here tracks the path depth reached through the guided fuzzing process. In essence: the initial test cases supplied by the user are considered "level 1". The test cases that can be derived from that through traditional fuzzing are considered "level 2"; the ones derived by using these as inputs to subsequent fuzzing rounds are "level 3"; and so forth. The maximum depth is therefore a rough proxy for how much value you're getting out of the instrumentation-guided approach taken by `afl-fuzz`.

The next field shows you the number of inputs that have not gone through any fuzzing yet. The same stat is also given for "favored" entries that the fuzzer really wants to get to soon. Next, we have the number of latent entries discovered after the first queue cycle; and the number of paths that seemingly result in variable behavior in the tested binary.

That last bit is actually fairly interesting: intentional variations - e.g., due to the explicit use of randomness - are possible, but tend to be very rare; in most cases, it may be a sign of unintentional randomness caused by the use of uninitialized memory in presence of ASLR.