#summary Tips for understanding the status screen

=american fuzzy lop: understanding the status screen=

When running `afl-fuzz`, the status screen should look roughly the following way:

{{{

                       american fuzzy lop 0.39b (xmllint)

┌─ process timing ─────────────────────────────────────┬─ overall results ─────┐
│        run time : 0 days, 8 hrs, 32 min, 43 sec      │  cycles done : 0      │
│   last new path : 0 days, 0 hrs, 6 min, 40 sec       │  total paths : 2095   │
│ last uniq crash : none seen yet                      │ uniq crashes : 0      │
│  last uniq hang : 0 days, 1 hrs, 24 min, 32 sec      │   uniq hangs : 19     │
├─ cycle progress ────────────────────┬─ map coverage ─┴───────────────────────┤
│  now processing : 1296 (61.86%)     │    map density : 4763 (29.07%)         │
│ paths timed out : 0 (0.00%)         │ count coverage : 4.03 bits/tuple       │
├─ stage progress ────────────────────┼─ findings in depth ────────────────────┤
│  now trying : interest 32/8         │ favored paths : 879 (41.96%)           │
│ stage execs : 3996/34.4k (11.62%)   │  new edges on : 423 (20.19%)           │
│ total execs : 27.4M                 │ total crashes : 0 (0 unique)           │
│  exec speed : 891.7/sec             │   total hangs : 24 (19 unique)         │
├─ fuzzing strategy yields ───────────┴───────────────┬─ path geometry ────────┤
│   bit flips : 57/289k, 18/289k, 18/288k             │   levels : 5           │
│  byte flips : 0/36.2k, 4/35.7k, 7/34.6k             │  pending : 1570        │
│ arithmetics : 53/2.54M, 0/537k, 0/55.2k             │ pend fav : 583         │
│  known ints : 8/322k, 12/1.32M, 10/1.70M            │   latent : 0           │
│       havoc : 1903/20.0M, 0/0                       │ variable : 0           │
└─────────────────────────────────────────────────────┴────────────────────────┘
}}}

This page provides an overview for each of the displayed stats.

==Process timing==

This section is fairly self-explanatory: it tells you how run the fuzzer has been running and how much time has elapsed since its most recent finds: "paths" (a shorthand for test cases that trigger new execution paths), crashes, and hangs.

When it comes to timing: there is no hard rule, but most fuzzing jobs should be expected to run for days or weeks. Some run for months.

There's one important thing to watch out for: if the tool is not finding new paths within several minutes of starting, you're probably not invoking the target binary correctly and it never gets to parse the input files we're throwing at it. If that's the case, you will eventually see a big red warning in this section, too.

==Overall results==

The first field in this section gives you the count of queue passes done so far - that is, the number of times the fuzzer went over all the interesting test cases, fuzzed them, and looped back. Every fuzzing session should be allowed to complete at least one cycle - and ideally, much more than that.

The remaining fields should be pretty obvious: there's the number of test cases ("paths") discovered so far, and the number of unique faults. The test cases, crashes, and hangs can be explored in real-time by browsing the output directory.

==Cycle progress==

This tells you how far along the fuzzer is with the current queue cycle: the test case it is currently working on, plus the number of inputs it decided to ditch because they were persistently timing out.

==Map coverage==

The section provides some trivia about the instrumentation embedded in the target binary. The first one tells you how many branch tuples we have already hit, in proportion to how much the bitmap can hold (ideally, this should be between 5 and 30%). The other deals with the variability in tuple hit counts.

==Stage progress==

This is the in-depth peek at what the fuzzer is actually doing right now. It tells you about the current stage, which can be any of:

  * `calibration` - a pre-fuzzing stage where the execution path is examined to detect anomalies.

  * `bitflip L/S` - deterministic bit flips. There are L bits toggled at any given time, walking the input file at S-bit increments. The current L/S variants are: 1/1, 2/1, 4/1, 8/8, 16/8, 32/8.

  * `arith L/8` - deterministic arithmetics. The fuzzer tries to subtract or add small integers to 8-, 16-, and 32-bit values. The steopver is always 8 bits.

  * `interest L/8` - deterministic value overwrite. The fuzzer has a list of known "interesting" 8-, 16-, and 32-bit values to try. The stepover is 8 bits.

  * `havoc` - a sort-of-fixed-length cycle with stacked random tweaks. The operations attempted during this stage include bit flips, overwrites with random and "interesting" integers, block deletion, and block duplication.

  * `splice` - a last-resort strategy that kicks in after a full queue cycle with no new paths. It is equivalent to havoc, except that it first splices together two random inputs from the queue at some arbitrarily selected midpoint.

The remaining fields should be fairly self-evident: there's the exec count progress indicator for the current stage, a global exec counter, and a benchmark for program execution speed. That benchmark should be ideally over 500 execs/sec - and if it drops below 100, the job will probably take very long time.

==Findings in depth==

This gives you several metrics that are of interest mostly to complete nerds, including the number of paths that the fuzzer likes the most based on a minimization algorithm baked into the code (these will get more air time), the number of test cases that actually result in better edge coverage (versus just pushing the hit counters up), and additional counters for crashes and hangs.

==Fuzzing strategy yields==

Another nerd-targeted section keeping track of how many paths do we get, in proportion to the number of execs attempted, for every fuzzing strategy. This mostly serves to scientifically validate assumptions about the usefulness of the approaches taken by `afl-fuzz`.

==Path geometry==

The first field here tracks the depth reached by the guided fuzzing process. In essence: the initial test cases supplied by the user are considered "level 1". The test cases that can be derived from that through traditional fuzzing are considered "level 2"; the ones derived by using these as inputs to subsequent fuzzing rounds are "level 3", etc. This is a rough proxy for how much value you're getting out of the instrumentation-guided approach taken by `afl-fuzz`.

The remaining fields indicate the number of inputs that have not gone through any fuzzing yet, and the same stat for "favored" entries that the fuzzer really wants to get to soon; the number of latent entries discovered after the first queue cycle; and the number of paths that seemingly result in variable behavior in the tested binary.

That last bit is actually fairly interesting: intentional variations are possible, but tend to be very rare; in most cases, it may be a sign of unintentional randomness caused by factors such as ASLR.